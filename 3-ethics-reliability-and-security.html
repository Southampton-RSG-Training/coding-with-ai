<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en" data-bs-theme="auto"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><title>Coding with AI: Opportunities and Responsibilities for Researchers: Ethics, Reliability and Security Considerations</title><meta name="viewport" content="width=device-width, initial-scale=1"><script src="assets/themetoggle.js"></script><link rel="stylesheet" type="text/css" href="assets/styles.css"><script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="favicons/incubator/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="favicons/incubator/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="favicons/incubator/favicon-16x16.png"><link rel="manifest" href="favicons/incubator/site.webmanifest"><link rel="mask-icon" href="favicons/incubator/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" media="(prefers-color-scheme: light)" content="white"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="black"></head><body>
    <header id="top" class="navbar navbar-expand-md top-nav incubator"><svg xmlns="http://www.w3.org/2000/svg" class="d-none"><symbol id="check2" viewbox="0 0 16 16"><path d="M13.854 3.646a.5.5 0 0 1 0 .708l-7 7a.5.5 0 0 1-.708 0l-3.5-3.5a.5.5 0 1 1 .708-.708L6.5 10.293l6.646-6.647a.5.5 0 0 1 .708 0z"></path></symbol><symbol id="circle-half" viewbox="0 0 16 16"><path d="M8 15A7 7 0 1 0 8 1v14zm0 1A8 8 0 1 1 8 0a8 8 0 0 1 0 16z"></path></symbol><symbol id="moon-stars-fill" viewbox="0 0 16 16"><path d="M6 .278a.768.768 0 0 1 .08.858 7.208 7.208 0 0 0-.878 3.46c0 4.021 3.278 7.277 7.318 7.277.527 0 1.04-.055 1.533-.16a.787.787 0 0 1 .81.316.733.733 0 0 1-.031.893A8.349 8.349 0 0 1 8.344 16C3.734 16 0 12.286 0 7.71 0 4.266 2.114 1.312 5.124.06A.752.752 0 0 1 6 .278z"></path><path d="M10.794 3.148a.217.217 0 0 1 .412 0l.387 1.162c.173.518.579.924 1.097 1.097l1.162.387a.217.217 0 0 1 0 .412l-1.162.387a1.734 1.734 0 0 0-1.097 1.097l-.387 1.162a.217.217 0 0 1-.412 0l-.387-1.162A1.734 1.734 0 0 0 9.31 6.593l-1.162-.387a.217.217 0 0 1 0-.412l1.162-.387a1.734 1.734 0 0 0 1.097-1.097l.387-1.162zM13.863.099a.145.145 0 0 1 .274 0l.258.774c.115.346.386.617.732.732l.774.258a.145.145 0 0 1 0 .274l-.774.258a1.156 1.156 0 0 0-.732.732l-.258.774a.145.145 0 0 1-.274 0l-.258-.774a1.156 1.156 0 0 0-.732-.732l-.774-.258a.145.145 0 0 1 0-.274l.774-.258c.346-.115.617-.386.732-.732L13.863.1z"></path></symbol><symbol id="sun-fill" viewbox="0 0 16 16"><path d="M8 12a4 4 0 1 0 0-8 4 4 0 0 0 0 8zM8 0a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 0zm0 13a.5.5 0 0 1 .5.5v2a.5.5 0 0 1-1 0v-2A.5.5 0 0 1 8 13zm8-5a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2a.5.5 0 0 1 .5.5zM3 8a.5.5 0 0 1-.5.5h-2a.5.5 0 0 1 0-1h2A.5.5 0 0 1 3 8zm10.657-5.657a.5.5 0 0 1 0 .707l-1.414 1.415a.5.5 0 1 1-.707-.708l1.414-1.414a.5.5 0 0 1 .707 0zm-9.193 9.193a.5.5 0 0 1 0 .707L3.05 13.657a.5.5 0 0 1-.707-.707l1.414-1.414a.5.5 0 0 1 .707 0zm9.193 2.121a.5.5 0 0 1-.707 0l-1.414-1.414a.5.5 0 0 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .707zM4.464 4.465a.5.5 0 0 1-.707 0L2.343 3.05a.5.5 0 1 1 .707-.707l1.414 1.414a.5.5 0 0 1 0 .708z"></path></symbol></svg><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-8">
      <div class="large-logo">
        <img id="incubator-logo" alt="Lesson Description" src="assets/images/incubator-logo.svg"><span class="badge text-bg-danger">
          <abbr title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.">
            <a href="https://docs.carpentries.org/resources/curriculum/lesson-life-cycle.html" class="external-link alert-link">
              <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
              Pre-Alpha
            </a>
            <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
          </abbr>
        </span>

      </div>
    </div>
    <div class="selector-container">
      <div id="theme-selector">
        <li class="nav-item dropdown" id="theme-button-list">
          <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
            <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="bd-theme-text"><li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                Light
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                Dark
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
            <li>
              <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                Auto
                <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
            </li>
          </ul></li>
      </div>


      <div class="dropdown" id="instructor-dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1"><li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/3-ethics-reliability-and-security.html';">Instructor View</button></li>
        </ul></div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Lesson Description" src="assets/images/incubator-logo-sm.svg"></div>
    <div class="lesson-title-md">
      Coding with AI: Opportunities and Responsibilities for Researchers
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="Search the All In One page" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0"><li class="nav-item">
          <span class="lesson-title">
            Coding with AI: Opportunities and Responsibilities for Researchers
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown"><li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul></li>
      </ul></div>
    <!--
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
      <input class="form-control me-2 searchbox" type="search" placeholder="" aria-label="">
        <button class="btn btn-outline-success tablet-search-button"  type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="Search the All In One page"></i>
        </button>
      </fieldset>
    </form>
    -->
    <a id="search-button" class="btn btn-primary" href="aio.html" role="button" aria-label="Search the All In One page">Search the All In One page</a>
  </div><!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Coding with AI: Opportunities and Responsibilities for Researchers
</div>

<aside class="col-md-12 lesson-progress"><div style="width: 67%" class="percentage">
    67%
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: 67%" aria-valuenow="67" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row" id="theme-row-mobile">
            <div class="col" id="theme-selector">
              <li class="nav-item dropdown" id="theme-button-list">
                <button class="btn btn-link nav-link px-0 px-lg-2 dropdown-toggle d-flex align-items-center" id="bd-theme" type="button" aria-expanded="false" data-bs-toggle="dropdown" data-bs-display="static" aria-label="Toggle theme (auto)">
                  <svg class="bi my-1 theme-icon-active"><use href="#circle-half"></use></svg><span class="d-lg-none ms-1" id="bd-theme-text">Toggle Theme</span>
                </button>
                <ul class="dropdown-menu dropdown-menu-right" aria-labelledby="bd-theme-text"><li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="light" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#sun-fill"></use></svg>
                      Light
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center" data-bs-theme-value="dark" aria-pressed="false">
                      <svg class="bi me-2 theme-icon"><use href="#moon-stars-fill"></use></svg>
                      Dark
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                  <li>
                    <button type="button" class="btn dropdown-item d-flex align-items-center active" data-bs-theme-value="auto" aria-pressed="true">
                      <svg class="bi me-2 theme-icon"><use href="#circle-half"></use></svg>
                      Auto
                      <svg class="bi ms-auto d-none"><use href="#check2"></use></svg></button>
                  </li>
                </ul></li>
            </div>
          </div>
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/3-ethics-reliability-and-security.html">Instructor View</a>
                      </div>
                    </div>
                  </div><!--/div.accordion-item-->
                </div><!--/div.accordion-flush-->
              </div><!--div.sidenav-view-selector -->
            </div><!--/div.col -->

            <hr></div><!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="1-ai-landscape.html">1. The AI Landscape</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="2-ai-assisted-coding.html">2. AI-Assisted Coding</a>
    </div><!--/div.accordion-header-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlushcurrent">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-headingcurrent">
      <button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapsecurrent" aria-expanded="true" aria-controls="flush-collapsecurrent">
        <span class="visually-hidden">Current Chapter</span>
        <span class="current-chapter">
        3. Ethics, Reliability and Security Considerations
        </span>
      </button>
    </div><!--/div.accordion-header-->

    <div id="flush-collapsecurrent" class="accordion-collapse collapse show" aria-labelledby="flush-headingcurrent" data-bs-parent="#accordionFlushcurrent">
      <div class="accordion-body">
        <ul><li><a href="#accuracy-and-reliability-of-ai-generated-code">Accuracy and Reliability of AI-Generated Code</a></li>
<li><a href="#data-privacy-security-risks-and-confidentiality">Data Privacy, Security Risks, and Confidentiality</a></li>
<li><a href="#intellectual-property-authorship-and-citation-of-ai-generated-code-and-text">Intellectual Property, Authorship, and Citation of AI-Generated Code
and Text</a></li>
<li><a href="#ethical-considerations-in-ai-assisted-research">Ethical Considerations in AI-Assisted Research</a></li>
<li><a href="#de-skilling-and-overdependence-on-ai-in-research-computing">De-skilling and Overdependence on AI in Research Computing</a></li>
<li><a href="#mitigating-risks-best-practices-for-responsible-ai-use-in-research">Mitigating Risks: Best Practices for Responsible AI Use in
Research</a></li>
<li><a href="#references">References</a></li>
        </ul></div><!--/div.accordion-body-->
    </div><!--/div.accordion-collapse-->

  </div><!--/div.accordion-item-->
</div><!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width"><div class="accordion accordion-flush lesson-resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="lesson-resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul><li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul></div>
                </div>
              </div>
            </div>
            <hr class="half-width lesson-resources"><a href="aio.html">See all in one page</a>


            <hr class="d-none d-sm-block d-md-none"><div class="d-grid gap-1">

            </div>
          </div><!-- /div.accordion -->
        </div><!-- /div.sidebar-inner -->
      </nav></div><!-- /div.sidebar -->
  </div><!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-instructor.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <nav class="lesson-content mx-md-4" aria-label="Previous and Next Chapter"><!-- content for small screens --><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="2-ai-assisted-coding.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="index.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="2-ai-assisted-coding.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: AI-Assisted Coding
        </a>
        <a class="chapter-link float-end" href="index.html" rel="next">
          Home
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
      <hr></nav><main id="main-content" class="main-content"><div class="container lesson-content">
        <h1>Ethics, Reliability and Security Considerations</h1>
        <p>Last updated on 2026-01-23 |

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/3-ethics-reliability-and-security.md" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>



        <div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>

        

<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul><li>What are some risks of biased, inaccurate, or unreliable
AI-generated outputs?</li>
<li>How can the use of AI tools compromise data privacy, security, or
confidentiality in research and software development?</li>
<li>What intellectual property and authorship issues emerge when AI
contributes to code or written work?</li>
<li>What are the long-term consequences of researchers relying on AI
without developing core coding skills?</li>
<li>What best practices can ensure that AI is used responsibly,
ethically, and transparently in research workflows?</li>
</ul></div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul><li>Describe common sources of bias, inaccuracy, and unreliability in
AI-generated outputs.</li>
<li>Explain data privacy, confidentiality, and security risks associated
with using AI tools in coding and research contexts.</li>
<li>Summarize intellectual property, authorship, and citation
considerations related to AI-generated code and text.</li>
<li>Analyze the potential long-term consequences of researchers relying
on AI tools without developing foundational coding skills.</li>
<li>Examine ethical challenges introduced by AI-assisted research,
including accountability, transparency, and reproducibility.</li>
<li>Assess the appropriateness of AI tool usage in specific research or
coding scenarios.</li>
<li>Apply best practices to mitigate ethical, security, and
skills-related risks when using AI in research.</li>
<li>Develop personal or team-level guidelines for responsible and
ethical AI use in coding and data analysis workflows.</li>
</ul></div>
</div>
</div>
</div>
</div>
<div id="callout1" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div class="callout-inner">
<div class="callout-content">
<p>When using AI for coding assistance, you can imagine an AI tool as
being like a fresh computer science graduate with so much enthusiasm
they will never say ‘I can’t do it’, but no practical experience or
broad understanding.</p>
</div>
</div>
</div>
<section><h2 class="section-heading" id="accuracy-and-reliability-of-ai-generated-code">Accuracy and Reliability of AI-Generated Code<a class="anchor" aria-label="anchor" href="#accuracy-and-reliability-of-ai-generated-code"></a></h2>
<hr class="half-width"><p>For researchers, relying on AI-generated code carries significant
risks. Incorrect code can lead to flawed results, which may compromise
the validity of your research, damage your professional reputation, and
even necessitate a paper retraction.</p>
<p>AI coding assistants can produce both random and systematic errors,
threatening the reliability and reproducibility of your work. For
instance, a <a href="https://arxiv.org/pdf/2304.10778" class="external-link">study conducted
by researchers at Bilkent University</a> found that GitHub Copilot
generated correct code only 46.3% of the time. This underscores the
danger of depending solely on AI tools for critical research tasks
without careful review.</p>
<div class="section level3">
<h3 id="outdated-results">Outdated Results<a class="anchor" aria-label="anchor" href="#outdated-results"></a></h3>
<p>If the AI model’s training data does not contain recent developments,
AI-generated code can be outdated. This can be particularly problematic
in fields such as software development and scientific research, where
current knowledge is critical.</p>
<p>For example, an AI might suggest a function from an open-source
library that hasn’t been well-maintained over the past few years. If the
library has unpatched security flaws, these could propagate into the
project.</p>
</div>
<div class="section level3">
<h3 id="unreliable-results">Unreliable Results<a class="anchor" aria-label="anchor" href="#unreliable-results"></a></h3>
<p>AI models sometimes “hallucinate” information. In the absence of
relevant training data, a GPT model will fabricate information rather
than saying it doesn’t know.</p>
<p>For example, an artificial intelligence might suggest an optimisation
that causes a memory leak or a system crash that, if unchecked by the
developer, could lead to serious system failures in production
environments.</p>
</div>
<div class="section level3">
<h3 id="transparency-and-explainability">Transparency and Explainability<a class="anchor" aria-label="anchor" href="#transparency-and-explainability"></a></h3>
<p>Many AI coding assistants function as “black boxes,” offering code
suggestions without explaining the reasoning behind them. Without this
insight, researchers may find it difficult to verify or trust the
proposed solutions, increasing the risk of undetected errors propagating
into experimental results.</p>
<p>This lack of transparency has direct implications for research
reproducibility. If the logic behind AI-generated code is unclear, other
researchers may be unable to replicate your methods or results, even if
the code appears to run correctly. There may be subtle errors or
undocumented assumptions embedded in AI-generated solutions, which can
lead to inconsistencies across experiments or datasets, leading to
different results and undermining confidence in your findings.</p>
<p>While AI can accelerate coding, researchers must critically evaluate
every output, verify results against established methods, and remain
vigilant to subtle errors that could compromise both research validity
and professional credibility.</p>
<div id="vibe-coding" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="vibe-coding" class="callout-inner">
<h3 class="callout-title">Vibe Coding</h3>
<div class="callout-content">
<p>Vibe Coding is a term used to describe AI-assisted coding without a
structured plan, proper design, or architectural considerations.
Decisions are made on the fly, often based on intuition or immediate
needs rather than a thoughtful development strategy.</p>
<p>This can be fantastic for developing a quite prototype or trying out
an idea. However, coding in this way can also lead to some major
problems:</p>
<ul><li>Without planning the structure of your code at the start, programs
are likely to become messy and confusing, and this can introduce
mistakes into the code.</li>
<li>Outputs are likely to appear mostly correct and, while obvious
errors are usually caught, the subtle mistakes are easy to miss.</li>
<li>This approach is likely to lead to problems being discovered only
during the build or runtime phase instead of during design, which makes
them more time-consuming and costly to fix.</li>
</ul></div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="data-privacy-security-risks-and-confidentiality">Data Privacy, Security Risks, and Confidentiality<a class="anchor" aria-label="anchor" href="#data-privacy-security-risks-and-confidentiality"></a></h2>
<hr class="half-width"><div class="section level3">
<h3 id="data-privacy-and-confidentiality">Data Privacy and Confidentiality<a class="anchor" aria-label="anchor" href="#data-privacy-and-confidentiality"></a></h3>
<p>AI tools such as chatGPT process and may retain user inputs.
Therefore, it’s really important to be cautious that you don’t
accidentally share confidential code, sensitive datasets or proprietary
research methods. Depending on the settings of your AI tool, the
information you enter may be reused to improve the AI model and/or could
resurface in future outputs, creating risks around intellectual property
leakage, confidentiality breaches, or non-compliance with data
protection regulations.</p>
<p>When AI tools run in the cloud, your code or data may be transmitted
to external servers. This increases the risk of exposure during transfer
or through storage breaches. Even if data is anonymised, code structure
and comments can still reveal sensitive details about research methods
or system design.</p>
</div>
<div class="section level3">
<h3 id="insecure-ai-generated-code">Insecure AI-Generated Code<a class="anchor" aria-label="anchor" href="#insecure-ai-generated-code"></a></h3>
<p>AI assistants learn from large volumes of existing code, and this
code can contain both good and bad coding practices. As a result, they
may suggest insecure or outdated practices. A <a href="https://arxiv.org/pdf/2211.03622" class="external-link">2023 Stanford University
study</a> found that programmers who used AI assistants often produced
less secure code but at the same time, felt more confident that it was
secure - a risky combination!</p>
<p>For example, an AI tool might generate code that fails to properly
validate user input, leaving the system open to issues like SQL
injection or cross-site scripting. This might be difficult to spot, and
because the code looks right on the surface, these problems can be
missed.</p>
<p>If you are aware of security considerations relevant to your code,
include them in your prompt to help ensure the AI generates more secure
code.</p>
<div id="embed-a-security-conscience-into-the-ai" class="callout">
<div class="callout-square">
<i class="callout-icon" data-feather="bell"></i>
</div>
<span class="callout-header">Callout</span>
<div id="embed-a-security-conscience-into-the-ai" class="callout-inner">
<h3 class="callout-title">Embed a ‘security conscience’ into the AI</h3>
<div class="callout-content">
<p>A Security-Focused Guide for AI Code Assistant Instructions was
written by the OpenSSF Best Practices and the AI/ML Working Groups. The
guide suggests ways that you can improve the security of AI-generated
code by deliberately embedding security expectations into the prompts.
These might include:</p>
<ul><li>Secure coding best practices that are relevant for your code
(e.g. Input validation and output encoding, error handling and logging,
secure defaults and configurations, testing for security)</li>
<li>Reminders of software supply chain security (i.e. security of
suggested third-party libraries and dependencies)</li>
<li>Address relevant platform and runtime security considerations
(e.g. operating system, deployment considerations, mobile app
security)</li>
<li>Language-specific security considerations</li>
<li>Pointing the AI toward relevant security standards and
frameworks</li>
</ul><p>Note: Including security expectations in prompts requires knowledge
of relevant software security practices, so is outside the scope of this
novice course. However, it’s worth bearing in mind if you’re interested
in developing research software.</p>
</div>
</div>
</div>
</div>
<div class="section level3">
<h3 id="third-party-dependency-risks-in-ai-generated-code">Third-Party Dependency Risks in AI-Generated Code<a class="anchor" aria-label="anchor" href="#third-party-dependency-risks-in-ai-generated-code"></a></h3>
<p>AI tools will often generate code that includes external libraries or
frameworks without checking whether they are secure and appropriate for
your use case. This could lead to vulnerabilities in your code,
licensing issues, or compatibility problems, which can cause problems
later and be difficult to untangle or debug.</p>
<p>AI hallucinations of third-party libraries can also be a security
risk. ChatGPT sometimes hallucinates non-existent coding libraries in
its outputs. A <a href="https://www.securityweek.com/chatgpt-hallucinations-can-be-exploited-to-distribute-malicious-code-packages/" class="external-link">study
by the security company Vulcan</a> identified a cyberattack technique
where criminals could hijack these fake libraries by publishing a
malicious package in place of the library and hoping developers would
install the infected library based on the AI tool’s recommendation.</p>
</div>
</section><section><h2 class="section-heading" id="intellectual-property-authorship-and-citation-of-ai-generated-code-and-text">Intellectual Property, Authorship, and Citation of AI-Generated Code
and Text<a class="anchor" aria-label="anchor" href="#intellectual-property-authorship-and-citation-of-ai-generated-code-and-text"></a></h2>
<hr class="half-width"><div class="section level3">
<h3 id="intellectual-property-and-ownership">Intellectual Property and Ownership<a class="anchor" aria-label="anchor" href="#intellectual-property-and-ownership"></a></h3>
<p>Intellectual property rights (legal rights that protect creations of
the mind) for AI-generated code are currently evolving.</p>
<p>Currently in the UK, if AI is used to assist a human creator, the
content is the human’s own intellectual creation and the copyright
belongs to the human creator.</p>
<p>If there is no human author, the “author” for copyright purposes is
the person “by whom the arrangements necessary for the creation of the
work are undertaken.” For AI-generated code, this means that if the code
is truly without human creative input (for example produced entirely by
an AI tool in response to a prompt without the author shaping or
selecting the output creatively), the law would treat the person who set
up the process (for example the user or developer who provided the
prompts and triggered the AI) as the “author” of that computer-generated
work.</p>
<p>However, there’s ongoing debate about how this practically applies to
many forms of AI outputs, including software code, because:</p>
<ul><li>The statutory language was drafted long before modern AI and may not
map cleanly to current AI models.</li>
<li>UK authorities are actively consulting on whether to adjust or
clarify how AI-generated works should be treated in copyright law.</li>
<li>Ownership can depend on contractual terms (such as developer
agreements, employment contracts, or AI tool terms of service), which
may assign rights to an employer or platform rather than the individual
user.</li>
</ul><p>Separately from ownership of new AI outputs, generating code that
replicates or contains substantial parts of copyrighted works without
permission, such as code copied from existing proprietary systems, can
infringe the copyright of others. AI models are trained on a vast amount
of data that may include copyrighted material. While outputs from AI
tools are typically novel, there is a risk that generated code or text
may closely resemble existing sources. This could lead to copyright
infringement claims, particularly in commercial or open-source contexts.
If you use AI assistance with coding, you’ll need to be cautious about
the potential for this to occur.</p>
</div>
<div class="section level3">
<h3 id="authorship-and-academic-credit">Authorship and Academic Credit<a class="anchor" aria-label="anchor" href="#authorship-and-academic-credit"></a></h3>
<p>AI tools can influence research outputs, so to what extent should
their contribution be acknowledged? AI systems can’t be authors but not
disclosing their use can misrepresent the nature of the researchers’
work and raise academic integrity questions.</p>
<p>Many journals, conferences and funding bodies now require for any use
of AI to be disclosed. Being transparent about the use of AI may also
increase trust in the research community and support reproducibility of
research.</p>
</div>
<div class="section level3">
<h3 id="citation">Citation<a class="anchor" aria-label="anchor" href="#citation"></a></h3>
<p>The outputs of AI aren’t stable, they’re likely to vary depending on
prompt wording and the AI model version among other factors, so that
can’t be reliably cited in the same way as you would cite a research
paper or software package.</p>
<p>Several universities and libraries recommend citing the tool used
including version and date, describe how it was used and clearly
distinguish between AI and human contributions.</p>
</div>
<div class="section level3">
<h3 id="implications-for-open-source-and-reuse">Implications for Open Source and Reuse<a class="anchor" aria-label="anchor" href="#implications-for-open-source-and-reuse"></a></h3>
<p>If AI-generated code is added to an open-source project, a licensing
conflict may be accidentally introduced if the patterns or structures in
the code are derived from software with incompatible licences. Check the
project’s licence and contribution guidelines before making any
AI-assisted contributions.</p>
</div>
</section><section><h2 class="section-heading" id="ethical-considerations-in-ai-assisted-research">Ethical Considerations in AI-Assisted Research<a class="anchor" aria-label="anchor" href="#ethical-considerations-in-ai-assisted-research"></a></h2>
<hr class="half-width"><div class="section level3">
<h3 id="bias-in-ai-systems">Bias in AI Systems<a class="anchor" aria-label="anchor" href="#bias-in-ai-systems"></a></h3>
<p>AI coding and research assistants can perpetuate or amplify biases
present in their training data. This may result in outputs that:</p>
<ul><li>Favour certain demographic groups over others</li>
<li>Encode biased assumptions into code or analysis</li>
<li>Fail to meet ethical, legal, or regulatory standards</li>
</ul></div>
<div class="section level3">
<h3 id="avoid-over-trust-in-ai-and-keep-humans-in-control">Avoid Over-Trust in AI and Keep Humans in Control<a class="anchor" aria-label="anchor" href="#avoid-over-trust-in-ai-and-keep-humans-in-control"></a></h3>
<p>One of the most common, and least discussed, biases in AI use is the
tendency to over-value AI-generated outputs. Outputs from GPT systems
often have an authoritative tone, influencing the extent to which you
believe them, but it’s important to remember that they do not possess
understanding, intent, or ethical awareness. Human judgement must remain
at the centre of research, with AI tools used to support humans rather
than override them.</p>
<p>Researchers should avoid placing AI on a pedestal and instead:</p>
<ul><li>Treat AI outputs as suggestions, not truths</li>
<li>Emphasise the role of human creativity and critical thinking</li>
<li>Remember that the researcher should take responsibility for an
AI-generated code or other content they use</li>
</ul></div>
<div class="section level3">
<h3 id="ethical-ai-framework">Ethical AI Framework<a class="anchor" aria-label="anchor" href="#ethical-ai-framework"></a></h3>
<p>Vilas Dhar, a social entrepreneur focused on the ethical use of AI
and president of the Patrick J. McGovern Foundation, proposed an Ethical
AI Framework built on three pillars:</p>
<ol style="list-style-type: decimal"><li>Responsible data practices</li>
</ol><p>AI systems are only as ethical as the data they are trained on.
Researchers should consider:</p>
<ul><li>Where the training data comes from</li>
<li>Whether it reflects historical or societal biases</li>
<li>Whether those biases could be reproduced or amplified in AI
outputs</li>
</ul><ol start="2" style="list-style-type: decimal"><li>Boundaries around safe and appropriate use</li>
</ol><p>Not all tasks are suitable for AI assistance. Ethical use requires
clear boundaries around:</p>
<ul><li>What decisions AI tools are allowed to influence</li>
<li>What decisions must remain under human control</li>
<li>How AI outputs are reviewed before being acted upon</li>
<li>Whether the AI tool is appropriate for the task at hand</li>
</ul><p>AI should support research, not replace human responsibility or
accountability.</p>
<ol start="3" style="list-style-type: decimal"><li>Ethical AI use depends on understanding how tools generate their
recommendations. When AI systems operate as black boxes, it becomes
difficult to assess validity, fairness, or risk. Humans should ask:</li>
</ol><ul><li>How did the tool arrive at this suggestion?</li>
<li>What assumptions or patterns might be influencing the output?</li>
<li>Can the result be independently validated?</li>
</ul></div>
</section><section><h2 class="section-heading" id="de-skilling-and-overdependence-on-ai-in-research-computing">De-skilling and Overdependence on AI in Research Computing<a class="anchor" aria-label="anchor" href="#de-skilling-and-overdependence-on-ai-in-research-computing"></a></h2>
<hr class="half-width"><p>AI tools can significantly enhance productivity in research
computing, but excessive reliance on them introduces risks to research
quality, integrity, and long-term capability.</p>
<div class="section level3">
<h3 id="risks-of-de-skilling">Risks of De-skilling<a class="anchor" aria-label="anchor" href="#risks-of-de-skilling"></a></h3>
<p>Over-reliance on AI for coding can lead researchers to lose, or fail
to develop, core technical skills. When you do not fully understand the
code you use, you can’t reliably verify whether AI-generated outputs are
correct, robust, or appropriate for their research context. As a result,
this may reduce confidence in the validity of published findings.</p>
<p>In addition to technical skills, excessive use of AI may also reduce
your critical evaluation skills. AI-generated code often appears
plausible, confident and well-structured, which can encourage blind
acceptance. This means that subtle errors, hidden assumptions, or
inappropriate methods may go unnoticed, particularly when your code gets
more complex.</p>
<p>There are also long-term implications for the research community. If
researchers become dependent on AI tools for fundamental software
development tasks, institutions risk losing the collective ability to
design, build, and maintain research software independently. This
creates problem if tools become unavailable, restricted, or unsuitable
for specific research needs.</p>
</div>
<div class="section level3">
<h3 id="ai-as-a-tool-not-a-replacement">AI as a Tool, Not a Replacement<a class="anchor" aria-label="anchor" href="#ai-as-a-tool-not-a-replacement"></a></h3>
<p>AI should be understood as a productivity tool that can accelerate
routine tasks and support problem-solving. Used thoughtfully, AI can
help explore ideas, generate boilerplate code, or suggest alternative
approaches.</p>
<p>However, maintaining human creativity and judgement is especially
critical in research, where novelty, insight, and deep understanding
often matter more than speed. AI can assist, but it cannot define
research questions, interpret results, or make ethical and
methodological decisions.</p>
</div>
</section><section><h2 class="section-heading" id="mitigating-risks-best-practices-for-responsible-ai-use-in-research">Mitigating Risks: Best Practices for Responsible AI Use in
Research<a class="anchor" aria-label="anchor" href="#mitigating-risks-best-practices-for-responsible-ai-use-in-research"></a></h2>
<hr class="half-width"><p>Responsible use of AI coding assistants requires a combination of
ethical awareness, technical safeguards, and disciplined research
practice. Here are some examples of ethical best practices, practices to
support research reproducibility and scientific validity, and some
security measures that you may put in place when using AI to assist with
research coding.</p>
<div class="section level3">
<h3 id="ethical-best-practices">Ethical Best Practices<a class="anchor" aria-label="anchor" href="#ethical-best-practices"></a></h3>
<ul><li>
<strong>Maintain human oversight:</strong> Researchers must
critically evaluate all AI-generated outputs, remaining alert to
potential bias, errors, or inappropriate assumptions.</li>
<li>
<strong>Test and validate rigorously:</strong> AI-generated code
should be treated as untrusted by default. Apply thorough testing and
validation to ensure correctness, reliability, and fitness for
purpose.</li>
<li>
<strong>Protect sensitive data:</strong> Avoid submitting
proprietary code, confidential data, or sensitive research materials to
online AI tools. If you use these materials for your research and have
decided to use AI, you may want to investigate locally hosted or offline
AI assistants to reduce data exposure risks.</li>
<li>
<strong>Define clear usage guidelines:</strong> Establish and follow
explicit policies for AI use in research computing. These may draw on
recognised frameworks such as the <a href="https://www.acm.org/code-of-ethics" class="external-link">ACM Code of Ethics</a> or the
<a href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai" class="external-link">European
Commission’s Ethical Guidelines on AI</a>, alongside
institution-specific policies.</li>
</ul></div>
<div class="section level3">
<h3 id="supporting-reproducibility-and-scientific-validity">Supporting Reproducibility and Scientific Validity<a class="anchor" aria-label="anchor" href="#supporting-reproducibility-and-scientific-validity"></a></h3>
<p>To maintain transparency, reproducibility, and scientific validity
when using AI tools, researchers should:</p>
<ul><li>
<strong>Document AI involvement:</strong> Record when, how, and why
AI-generated suggestions were used or modified.</li>
<li>
<strong>Validate against known results:</strong> Test AI-generated
code using benchmarks, reference datasets, or established methods before
integration.</li>
<li>
<strong>Combine AI with domain expertise:</strong> Use AI to support
human judgement and subject-matter knowledge, rather than replacing
them.</li>
</ul></div>
<div class="section level3">
<h3 id="security-measures">Security Measures<a class="anchor" aria-label="anchor" href="#security-measures"></a></h3>
<ul><li>
<strong>Mandatory code review:</strong> Review all AI-generated
code, ideally using standard code review processes, to identify
vulnerabilities, logic errors, or unsafe practices.</li>
<li>
<strong>Secure development practices:</strong> If you’re working on
a larger piece of research software, integrate security testing tools
into development workflows and ensure researchers are trained in secure
coding principles.</li>
<li>
<strong>Protect access and data:</strong> Use access controls and
encryption to safeguard codebases and datasets from unauthorised access
by AI tools.</li>
</ul><div id="personal-ethics-and-security-policy" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<span class="callout-header">Challenge</span>
<div id="personal-ethics-and-security-policy" class="callout-inner">
<h3 class="callout-title">Personal Ethics and Security Policy</h3>
<div class="callout-content">
<p>Write a short personal policy outlining how you will use AI tools
responsibly when coding. Include at least <strong>three clear
guidelines</strong>.</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1"> Show me the solution </h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Your guidelines could include:</p>
<ul><li>Always document when and how AI tools are used.</li>
<li>Make sure I understand any code generated by AI before using it for
my research.</li>
<li>Never input sensitive, personal, or proprietary data into AI
systems.</li>
<li>Take full responsibility for my research code, even when it is AI
generated.</li>
<li>Maintain my critical thinking and decision making skills, never
allow AI to do these things for me.</li>
</ul></div>
</div>
</div>
</div>
</div>
</section><section><h2 class="section-heading" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
<hr class="half-width"><ul><li><a href="https://carpentries-incubator.github.io/gen-ai-coding/3-ethical-and-security-considerations.html" class="external-link">AI-Assisted
Coding with Codium, Ethical and Security Considerations</a></li>
<li><a href="https://arxiv.org/pdf/2211.03622" class="external-link">Perry, N., Srivastava,
M., Kumar, D., &amp; Boneh, D. (2023, November). Do users write more
insecure code with ai assistants?. In Proceedings of the 2023 ACM SIGSAC
conference on computer and communications security
(pp. 2785-2799)</a></li>
<li><a href="https://arxiv.org/pdf/2304.10778" class="external-link">Yetiştiren, B., Özsoy,
I., Ayerdem, M., &amp; Tüzün, E. (2023). Evaluating the code quality of
ai-assisted code generation tools: An empirical study on github copilot,
amazon codewhisperer, and chatgpt. arXiv preprint
arXiv:2304.10778.</a></li>
<li><a href="https://www.gov.uk/government/consultations/copyright-and-artificial-intelligence/copyright-and-artificial-intelligence?utm_source=chatgpt.com" class="external-link">UK
Government Consultation on Copyright and Artificial
Intelligence</a></li>
<li><a href="https://guides.library.duke.edu/citing/AI?utm_source=chatgpt.com" class="external-link">Duke
University Libraries guide to citing artificial intelligence</a></li>
<li><a href="https://cgsandesh.medium.com/ethical-ai-framework-by-vilas-dhar-6c3b243d587c" class="external-link">Ethical
AI Framework by Vilas Dhar</a></li>
<li><a href="https://www.linkedin.com/learning/what-is-generative-ai" class="external-link">What is
Generative AI? - LinkedIn Learning</a></li>
<li><a href="https://best.openssf.org/Security-Focused-Guide-for-AI-Code-Assistant-Instructions" class="external-link">Security
Focused Guide for AI Code Assistant Instructions</a></li>
<li><a href="https://www.securityweek.com/chatgpt-hallucinations-can-be-exploited-to-distribute-malicious-code-packages/" class="external-link">ChatGPT
Hallucinations Can Be Exploited to Distribute Malicious Code
Packages</a></li>
</ul><!--
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use.
 --></section></div> <!-- / div.lesson-content -->
    </main><!-- / main#main-content.main-content --><nav class="bottom-pagination mx-md-4" aria-label="Previous and Next Chapter"><div class="d-block d-sm-block d-md-none">
        <a class="chapter-link" href="2-ai-assisted-coding.html"><i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>Previous</a>
        <a class="chapter-link float-end" href="index.html">Next<i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i></a>
      </div>
      <!-- content for large screens -->
      <div class="d-none d-sm-none d-md-block">
        <a class="chapter-link" href="2-ai-assisted-coding.html" rel="prev">
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-left"></i>
          Previous: AI-Assisted Coding
        </a>
        <a class="chapter-link float-end" href="index.html" rel="next">
          Home
          <i aria-hidden="true" class="small-arrow" data-feather="arrow-right"></i>
        </a>
      </div>
    </nav></div> <!-- / div.primary-content.col-xs-12 -->
<!-- END:   inst/pkgdown/templates/content-instructor.html-->

      </div><!--/div.row-->
      		<footer class="row footer mx-md-3"><hr><div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>

        <a href="https://github.com/carpentries/workbench-template-md/edit/main/episodes/3-ethics-reliability-and-security.md" class="external-link">Edit on GitHub</a>

	
        | <a href="https://github.com/carpentries/workbench-template-md/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/carpentries/workbench-template-md/" class="external-link">Source</a></p>
        <p>
        <a href="citation.html">Cite</a>
        | <a href="mailto:p.k.broadbent@soton.ac.uk">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
		</div>
		<div class="col-md-6">

        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>

        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.18.4" class="external-link">sandpaper (0.18.4)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.9" class="external-link">pegboard (0.7.9)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.9" class="external-link">varnish (1.0.9)</a></p>
		</div>
		</footer></div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "LearningResource",
  "@id": "https://carpentries.github.io/workbench-template-md/3-ethics-reliability-and-security.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/LearningResource/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "AI, GPT, LLM, software",
  "name": "Ethics, Reliability and Security Considerations",
  "creativeWorkStatus": "active",
  "url": "https://carpentries.github.io/workbench-template-md/3-ethics-reliability-and-security.html",
  "identifier": "https://carpentries.github.io/workbench-template-md/3-ethics-reliability-and-security.html",
  "dateCreated": "2026-09-01",
  "dateModified": "2026-01-23",
  "datePublished": "2026-01-23"
}

  </script><script>
		feather.replace();
	</script></body></html><!-- END:   inst/pkgdown/templates/layout.html-->

